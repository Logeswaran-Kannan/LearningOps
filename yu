# Define a function to fetch table names and their columns excluding tables starting with '__apply'
def fetch_table_columns_with_date(schema):
    table_columns = []

    # Query to fetch table names
    tables_query = f"SHOW TABLES IN {schema}"
    tables_df = spark.sql(tables_query)

    # Iterate through each table
    for table_row in tables_df.collect():
        table_name = table_row["tableName"]

        # Exclude tables starting with '__apply'
        if not table_name.startswith("__apply"):
            columns = []

            # Query to fetch columns in the table that contain 'date'
            columns_query = f"DESCRIBE {schema}.{table_name}"
            columns_df = spark.sql(columns_query)

            # Iterate through each column and check for 'date' in the column name
            for column_row in columns_df.collect():
                column_name = column_row["col_name"]
                if "date" in column_name.lower():
                    columns.append(column_name)

            # If columns with 'date' are found, add to the result list
            if columns:
                table_columns.append({"Table": table_name, "Date Columns": columns})

    return table_columns
