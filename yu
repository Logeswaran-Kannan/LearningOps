# Import necessary libraries
import pandas as pd
from pyspark.sql import SparkSession

# Define function to get table count for a given database
def get_table_count(database_name):
    # Initialize Spark session
    spark = SparkSession.builder.appName("TableCount").getOrCreate()

    # Get the list of tables in the specified database
    tables = spark.sql(f"SHOW TABLES IN {database_name}").toPandas()

    # Initialize an empty list to store results
    results = []

    # Iterate through the tables
    for _, table_row in tables.iterrows():
        table_name = table_row["tableName"]
        count = spark.sql(f"SELECT COUNT(*) FROM {database_name}.{table_name}").first()[0]

        # Exclude tables based on specified conditions
        if not (table_name.startswith("--") or table_name.endswith("temp") or table_name.startswith("aren")):
            comment = spark.sql(f"DESCRIBE EXTENDED {database_name}.{table_name}").filter("col_name = 'Comment'").collect()[0][1]
            results.append([database_name, table_name, count, comment])

    # Stop the Spark session
    spark.stop()

    return results

# Get table count for a specific database
database_name_input = "your_database_name"
table_counts = get_table_count(database_name_input)

# Convert results to a Pandas DataFrame
result_df = pd.DataFrame(table_counts, columns=["Database", "Table", "Count", "Comment"])

# Filter tables with count > 0 or with specified comments
result_df_filtered = result_df[result_df["Count"] > 0 | (result_df["Count"] == 0 & result_df["Comment"].str.contains("no data"))]

# Generate HTML report
html_report = result_df_filtered.to_html(index=False)

# Display or save the HTML report
print(html_report)
# Optionally, you can save the HTML report to a file
# result_df_filtered.to_html("table_counts_report.html", index=False)
