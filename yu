# JDBC URL for connecting to the PostgreSQL database
jdbc_url = "jdbc:postgresql://your_host:your_port/your_database"

# JDBC driver class
jdbc_driver = "org.postgresql.Driver"

# Database connection properties
connection_properties = {
    "user": "your_username",
    "password": "your_password",
    "driver": jdbc_driver
}

# Table name pattern to filter only tables from the kingfisher_core schema
table_pattern = "kingfisher_core.%"

# Spark SQL query to fetch table names and columns containing 'date'
query = f"""
    SELECT table_name, column_name
    FROM information_schema.columns
    WHERE table_schema = 'kingfisher_core'
    AND column_name LIKE '%date%'
"""

# Load data using JDBC
df = spark.read.jdbc(url=jdbc_url, table="information_schema.columns", properties=connection_properties)

# Filter tables and columns containing 'date'
filtered_df = df.filter((df.table_schema == 'kingfisher_core') & (df.column_name.contains('date')))

# Show the results
filtered_df.show()
