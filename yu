from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Initialize Spark session
spark = SparkSession.builder.appName("JSONProcessing").getOrCreate()

# Specify your table and column names
source_table_name = "your_source_table"
source_column_name = "body"

# Read the JSON data into a Spark DataFrame
json_data = spark.sql(f"SELECT * FROM {source_table_name}")

# Extract fields from the nested JSON structure
result_df = json_data.select(
    col(source_column_name + ".field1").alias("Field1"),
    col(source_column_name + ".field2").alias("Field2"),
    col(source_column_name + ".field3.nestedField").alias("NestedField"),
    col(source_column_name + ".field3.anotherNestedField").alias("AnotherNestedField")
)

# Show the result DataFrame
result_df.show(truncate=False)

# Write the result DataFrame to a new table
result_table_name = "result_table"
result_df.write.mode("overwrite").saveAsTable(result_table_name)

# Stop the Spark session
spark.stop()
