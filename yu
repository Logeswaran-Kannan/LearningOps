df = spark.read.json(spark.sparkContext.parallelize([json_data]))

# Flatten the nested structure
flat_df = df.select(
    "registration",
    "make",
    "model",
    "firstUsedDate",
    "fuelType",
    "primaryColour",
    "vehicleId",
    "registrationDate",
    "manufactureDate",
    "engineSize",
    explode(col("motTests")).alias("motTest")
).select(
    "registration",
    "make",
    "model",
    "firstUsedDate",
    "fuelType",
    "primaryColour",
    "vehicleId",
    "registrationDate",
    "manufactureDate",
    "engineSize",
    "motTest.completedDate",
    "motTest.testResult",
    "motTest.expiryDate",
    "motTest.odometerValue",
    "motTest.odometerUnit",
    "motTest.odometerResultType",
    "motTest.motTestNumber",
    "motTest.rfrAndComments"
)

# Show the result
flat_df.show(truncate=False)
