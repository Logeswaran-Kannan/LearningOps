from pyspark.sql import SparkSession
from pyspark.sql.functions import col, explode

# Initialize Spark session
spark = SparkSession.builder.appName("JSONFlattener").getOrCreate()

# Sample data with a column named 'body' containing nested JSON
data = [
    (1, '{"id": 1, "name": "Parent", "children": [{"id": 11, "name": "Child1", "grandchildren": [{"id": 111, "name": "Grandchild1"}, {"id": 112, "name": "Grandchild2"}]}, {"id": 12, "name": "Child2"}]}'),
    (2, '{"id": 2, "name": "AnotherParent", "children": [{"id": 21, "name": "AnotherChild1"}]}')
]

# Define schema
schema = ["parent_id", "body"]

# Create DataFrame
df = spark.createDataFrame(data, schema=schema)

# Explode the 'children' array to create a new row for each child
exploded_df = df.select("parent_id", explode(col("body.children")).alias("child"))

# Extract values from the nested JSON structure
result_df = exploded_df.select(
    "parent_id",
    col("child.id").alias("child_id"),
    col("child.name").alias("child_name"),
    explode(col("child.grandchildren")).alias("grandchild")
).select(
    "parent_id",
    "child_id",
    "child_name",
    col("grandchild.id").alias("grandchild_id"),
    col("grandchild.name").alias("grandchild_name")
)

# Show the result DataFrame
result_df.show(truncate=False)

# Optionally, you can write the result DataFrame to an output table
output_table_name = "output_table"
result_df.write.mode("overwrite").saveAsTable(output_table_name)

# Stop the Spark session
spark.stop()
