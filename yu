from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Initialize Spark session
spark = SparkSession.builder.appName("JSONExtractor").getOrCreate()

# Specify your table and column names
table_name = "your_table"
column_name = "your_json_column"

# Read the JSON data into a Spark DataFrame
json_data = spark.sql(f"SELECT {column_name} FROM {table_name} LIMIT 10")

# Extract specific values from the JSON structure
result_df = json_data.select(
    col(column_name + ".field1").alias("Field1"),
    col(column_name + ".nested.field2").alias("Field2"),
    col(column_name + ".anotherNested.field3").alias("Field3")
)

# Show the result DataFrame
result_df.show(truncate=False)

# Optionally, you can write the result DataFrame to an output table
output_table_name = "output_table"
result_df.write.mode("overwrite").saveAsTable(output_table_name)

# Stop the Spark session
spark.stop()
