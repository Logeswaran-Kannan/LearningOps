# Import necessary libraries
from pyspark.sql import SparkSession
from pyspark.sql.functions import col
from pyspark.sql.window import Window

# Define your source and target database names
source_database = "<source_database>"
target_database = "<target_database>"

# Initialize Spark session
spark = SparkSession.builder.appName("DataComparison").getOrCreate()

# Function to compare tables
def compare_tables(table_name):
    try:
        # Read source and target tables
        source_df = spark.table(f"{source_database}.{table_name}")
        target_df = spark.table(f"{target_database}.{table_name}")

        # Check if the column count matches
        if len(source_df.columns) != len(target_df.columns):
            return f"DDL mismatch for table '{table_name}'"

        # Exclude specified columns
        columns_to_exclude = ["source_system", "valid_from_dt"]
        source_columns = [col for col in source_df.columns if col not in columns_to_exclude]

        # Sample data from the source table
        source_sample = source_df.where(
            (col("sequence_by").between("2023-08-30T08:43:28.123+0000", "2023-09-04T08:43:28.123+0000"))
        ).limit(50)

        # Sample data from the target table
        target_sample = target_df.where(
            col("sequence_by").between("2023-08-30T08:43:28.123+0000", "2023-09-04T08:43:28.123+0000")
        ).limit(50)

        # Compare data
        if source_sample.subtract(target_sample).count() > 0:
            return f"Data mismatch for table '{table_name}'"
        else:
            return f"Data matches for table '{table_name}'"

    except Exception as e:
        return f"Error: {str(e)}"

# Get the list of tables in the source database (excluding excluded tables)
source_tables = spark.catalog.listTables(source_database)
source_table_names = [table.name for table in source_tables if not (
    table.name.startswith("__apply") or
    table.name.endswith("_table") or
    table.name.endswith("_prov_codes")
)]

# Iterate through the tables and compare them
results = []
for table_name in source_table_names:
    result = compare_tables(table_name)
    results.append(result)

# Print the results
for result in results:
    print(result)

# Stop the Spark session
spark.stop()
