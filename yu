from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Initialize Spark session
spark = SparkSession.builder.appName("JSONExtractor").getOrCreate()

# Example JSON data with parent and child structure
json_data = '''
[
  {
    "id": 1,
    "name": "Parent1",
    "details": {
      "child_id": 101,
      "child_name": "Child1"
    }
  },
  {
    "id": 2,
    "name": "Parent2",
    "details": {
      "child_id": 102,
      "child_name": "Child2"
    }
  }
]
'''

# Read the JSON data into a Spark DataFrame
df = spark.read.json(spark.sparkContext.parallelize([json_data]))

# Extract all fields from JSON into separate columns
result_df = df.select(
    col("id").alias("parent_id"),
    col("name").alias("parent_name"),
    col("details.child_id").alias("child_id"),
    col("details.child_name").alias("child_name")
)

# Show the result DataFrame
result_df.show(truncate=False)

# Optionally, you can write the result DataFrame to an output table
output_table_name = "output_table"
result_df.write.mode("overwrite").saveAsTable(output_table_name)

# Stop the Spark session
spark.stop()
