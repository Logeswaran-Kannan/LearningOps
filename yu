from pyspark.sql import SparkSession
from pyspark.sql.functions import from_json, explode, col

# Initialize Spark session
spark = SparkSession.builder.appName("NestedJSONProcessor").getOrCreate()

# Sample data with a parent-child relationship in the 'body' column
data = [
    (1, '{"id": 1, "name": "Parent", "children": [{"id": 101, "name": "Child1"}, {"id": 102, "name": "Child2"}]}'),
    (2, '{"id": 2, "name": "AnotherParent", "children": [{"id": 201, "name": "Child3"}]}')
]

# Create a DataFrame with sample data
schema = ["id", "body"]
df = spark.createDataFrame(data, schema=schema)

# Extract all fields from the JSON structure
processed_df = df.select("id", from_json("body", "{id: int, name: string, children: array<struct<id:int,name:string>>>}").alias("json_data")) \
                 .select("id", "json_data.*", explode("json_data.children").alias("child"))

# Show the result DataFrame
processed_df.show(truncate=False)

# Optionally, you can write the result DataFrame to an output table
output_table_name = "output_table"
processed_df.write.mode("overwrite").saveAsTable(output_table_name)

# Stop the Spark session
spark.stop()
