from pyspark.sql import SparkSession
from pyspark.sql.functions import col
from pyspark.sql.window import Window

# Initialize SparkSession
spark = SparkSession.builder.appName("DataComparison").getOrCreate()

# Define database and table exclusion patterns
exclude_table_patterns = ["__apply", "_table", "_prov_codes"]
exclude_columns = ["source_system", "valid_from_dt"]

# Define source and destination database names
source_database_name = "source_database"
destination_database_name = "destination_database"

# Function to perform data comparison for a table
def compare_table(table_name):
    # Read data from the source database
    source_df = spark.sql(f"SELECT * FROM {source_database_name}.{table_name} WHERE sequence_by BETWEEN '2023-08-30T08:43:28.123+0000' AND '2023-09-04T08:43:28.123+0000' LIMIT 50")

    # Read data from the destination database
    destination_df = spark.sql(f"SELECT * FROM {destination_database_name}.{table_name}")

    # Check if both source and destination tables exist
    if source_df.isEmpty():
        print(f"Table {table_name} is missing in the source database.")
    elif destination_df.isEmpty():
        print(f"Table {table_name} is missing in the destination database.")
    else:
        # Perform data comparison
        column_count_match = source_df.columns == destination_df.columns
        if column_count_match:
            data_match = source_df.subtract(destination_df).isEmpty()
            if data_match:
                print(f"Data in table {table_name} matches between source and destination.")
            else:
                print(f"Data in table {table_name} does not match between source and destination.")
        else:
            print(f"Column count does not match for table {table_name}.")

# Get the list of tables from the source database
source_tables = spark.sql(f"SHOW TABLES IN {source_database_name}").filter(~col("tableName").rlike("|".join(exclude_table_patterns)))

# Iterate over the tables and perform data comparison
for row in source_tables.collect():
    table_name = row["tableName"]
    compare_table(table_name)

# Stop the Spark session
spark.stop()
