from pyspark.sql import SparkSession
import os

# Create a Spark session
spark = SparkSession.builder.appName("FileSize").getOrCreate()

# Define the base folder path
base_folder_path = "/mnt/your_folder_path"  # Replace with your actual folder path

# Function to get file size in MB
def get_file_size(file_path):
    return os.path.getsize(file_path) / (1024 * 1024)  # Convert bytes to megabytes

# Get a list of all files in the folder and its subfolders
file_paths = [os.path.join(root, file) for root, dirs, files in os.walk(base_folder_path) for file in files]

# Create a Spark DataFrame with file paths
df = spark.createDataFrame(file_paths, "path STRING")

# Register a user-defined function (UDF) to calculate file size
spark.udf.register("get_file_size", get_file_size)

# Calculate file size for each file using the UDF
result = spark.sql("SELECT path, get_file_size(path) AS size_MB FROM __TABLE__")

# Show the result
result.show(truncate=False)

# Stop the Spark session
spark.stop()




Hello everyone,

I've outlined the plan for deploying the MOT ingestion to the pre-production environment. Julian, we're seeking your assistance in transferring the raw MOT DVSA files from the development (DEV) environment to pre-production (Pre-Prod). Initially, there are 700 files in the history folder that need to be moved to the corresponding history folder in pre-production. After this transfer, Venu will handle the processing of this data, progressing it from the bronze stage through analytical processes until it reaches the enrichment store.

Following this initial phase, Venu will notify you to proceed with moving the incremental files, which amount to 2,000 files. These estimates are based on the processing of 2,700 files in the lower environment. Your collaboration on this deployment is greatly appreciated.

