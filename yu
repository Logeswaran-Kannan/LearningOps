# Import necessary libraries
from pyspark.sql import SparkSession
import os

# Create a Spark session
spark = SparkSession.builder.appName("FileCountAndSize").getOrCreate()

# Define the remote mount folder path
remote_mount_folder = "/dbfs/mnt/your_remote_mount_folder"  # Replace with your actual remote mount folder path

# Function to get file size in MB
def get_file_size(file_path):
    return os.path.getsize(file_path) / (1024 * 1024)  # Convert bytes to megabytes

# List files in the remote mount folder
file_paths = dbutils.fs.ls(remote_mount_folder)

# Display count of files
print(f"Total files in {remote_mount_folder}: {len(file_paths)}")

# Display size of each file
for file_path_info in file_paths:
    file_path = file_path_info.path
    file_size_mb = get_file_size(file_path)
    print(f"File: {file_path}, Size: {file_size_mb:.2f} MB")

# Stop the Spark session
spark.stop()
