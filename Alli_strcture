üîß 1. Pre-Implementation Phase
‚úÖ Preparation & Planning (All Teams)
 Confirm resource allocation across all teams (BICOE, AZ Infra, Source System, QA, Downstream, Change Mgmt).

 Ensure all required PROD access is granted (Read Replica, Databricks PROD workspace, ADF PROD).

 Confirm test summary and sign-off document for BICOE dry run is finalized.

 Confirm runbook and rollback plan is reviewed and approved by stakeholders.

‚úÖ BICOE Tasks
 Send MI user communication regarding dry run window and data availability impact.

 Pause MI data pipelines to avoid ingesting incorrect or partial data during switch.

 Deploy ADF code and configuration changes to PROD (switch linked service to PROD Read Replica).

 Validate pipeline triggers are disabled temporarily to allow for manual control.

 Review and ensure all smoke test scripts are prepared and approved for post-deployment validation.

 Notify Azure Infra team to prepare for source switch.

‚úÖ AZ Infra / Source Team
 Prepare Guidewire Cloud PROD Read Replica and validate access from Data Factory & Databricks.

 Validate monitoring tools for Read Replica (query logs, CPU/memory, etc.).

 Confirm switch-over script/process is in place for Guidewire data source redirection.

‚úÖ QA / Validation Teams
 Ensure test datasets, use cases, and checkpoints are documented.

 Finalize baseline validation templates for post-switch comparison.

‚úÖ Checkpoints
 Pre-implementation checkpoint call (Dry Run Kickoff).

 Checklist review: Access, code deployments, scripts, comms sent, backout prep.

üîÅ 2. Implementation Phase
‚úÖ AZ Infra / Source Team
 Switch Guidewire source system from legacy Oracle to new Cloud version.

 Confirm handshake and readiness signal to BICOE after switch.

‚úÖ BICOE Tasks
 Manually trigger data pipelines from PROD ADF using new linked service.

 Monitor initial data load ‚Äì ensure expected volume, schema match, and no critical failures.

 Validate schema of data ingested from PROD Read Replica.

 Run smoke test scripts on Databricks against new data.

‚úÖ QA / Validation Teams
 Execute post-switch validation tests for key tables.

 Confirm format, record counts, null checks, and known defects.

‚úÖ Checkpoints
 Mid-implementation checkpoint call: Confirm source switched, data flow started, initial load healthy.

üß™ 3. Post-Implementation Phase
‚úÖ BICOE Tasks
 Full health check on Azure Data Factory, Databricks pipelines, and data completeness.

 Confirm metadata syncs (schemas, tables, logs).

 Run full smoke test and record results.

 Compare against historical data snapshots.

‚úÖ Downstream Impact & Communications
 Notify downstream teams (e.g., Marketing, MI, SPV, etc.) of data availability status.

 Confirm any temporary pauses (e.g., SPV team processing) are lifted with timing clarity.

 Document any new issues/defects and their mitigation steps.

‚úÖ Backout Planning (if triggered)
 Revert ADF linked service to legacy Oracle if major failure.

 Manually resume pipelines from fallback.

 Run backout smoke test scripts to confirm legacy source data intact.

 Communicate backout success to all teams and stakeholders.

‚úÖ Checkpoints
 Post-implementation checkpoint call: Validate system health, test results, defects.

 Backout window checkpoint (only if required).

‚úÖ 4. Closure Activities
‚úÖ All Teams
 Final dry run test results shared and signed off.

 Update runbook with learnings and issue logs.

 Submit change tasks closure in ServiceNow.

 Update rollback plan based on lessons from dry run.

 Confirm availability for production cutover readiness.

‚úÖ Change Management
 Finalize and document dry run outcome.

 Update RFC notes with successful execution and checklist.

 Confirm Go/No-Go criteria for production deployment.

‚úÖ Final Checkpoint
 Closure checkpoint call: Dry run wrap-up, post-mortem items, Go-Live prep.
------------------------------------------


‚úÖ Dry Run Runbook: Guidewire Cloud Upgrade in Production
üìå Pre-Implementation Phase
#	Task	Owner	Notes
1	Finalize test summary & sign-off documentation	BICOE	Ensure formal sign-offs for schema, data validation, and manual checks.
2	Confirm resource availability for all teams	Project PM	BICOE, AZ, GW App team, downstream teams.
3	Send communication to MI users about upcoming migration	BICOE	Include MI user outage window, impact scope.
4	Pause all MI pipelines	BICOE / Data Platform	Disable triggers in Azure Data Factory.
5	Deploy latest code package to production	BICOE	Includes schema alignment, ETL logic, and configuration scripts.
6	Update ADF linked services to point to PROD Read Replica	BICOE	Update securely using Key Vault references.
7	Review & confirm smoke test scripts	BICOE + QA	Ensure test coverage includes top-priority tables and known edge cases.
8	Pre-check: Validate access to PROD Read Replica & Databricks	BICOE / Security	Confirm required service principals and human access are working.
9	Schedule checkpoint call with all stakeholders	PMO	Define timing before, during, and after release.
10	Create ServiceNow change ticket & attach runbook	Project PM	Ensure backout steps and risk sections are detailed.
11	Validate orchestration availability and resource capacity in PROD	Data Platform	Confirm autoscaling, cluster quotas, SQL performance.

üîÅ Implementation Phase
#	Task	Owner	Notes
12	Confirm pre-migration checkpoint call (T-0)	PMO	All teams on-call and ready.
13	AZ Team: Switch GW source from non-cloud to cloud	AZ Team	Await explicit handshake from GW App team.
14	BICOE: Trigger data pipeline manually to pull from PROD Read Replica	BICOE	Monitor for load completion & any lag/delays.
15	ADF: Enable triggers if required for real-time sync	BICOE	Post verification of initial loads.
16	Monitor Azure Data Factory for pipeline failures	BICOE / Data Platform	Use alerts & dashboard checks.
17	Perform smoke tests for top 20 critical tables	BICOE / QA	Validate record counts, recent updates, business logic integrity.
18	Perform health checks on data platform	Data Platform	Validate cluster health, pipeline stats, ingestion logs.
19	Validate access to tables in Databricks / MI layer	MI Team	Confirm business users can read required views.
20	Confirm status on checkpoint call	PMO	Capture initial issues, risks, or delays.

üì¶ Post-Implementation Phase
#	Task	Owner	Notes
21	Notify MI users of resumption post-validation	BICOE	Include validation outcome summary.
22	Downstream impact analysis	BICOE + SPV/Marketing	Confirm no job failures or missing input for SPV, PowerBI, etc.
23	Confirm all data feeds are running as expected	Data Platform	Ensure scheduled triggers are enabled.
24	Risk and deviation log capture	PMO / BICOE	Record unplanned events, manual interventions.
25	Final checkpoint call (Go / No-Go Decision)	PMO	Ensure all criteria met for closure.
26	If all validations successful, update ServiceNow task to Complete	Project PM	Attach testing evidence and confirmation emails.
27	Archive and store runbook, test results, logs	BICOE	For audit & rollback tracking.

üîô Backout Plan (Only if Needed)
#	Task	Owner	Notes
28	Trigger rollback in ADF (switch linked service back to legacy Oracle)	BICOE	Requires rollback scripts pre-deployed.
29	AZ Team: Rollback source to previous GW instance	AZ Team	Requires GW App rollback readiness.
30	Disable cloud source pipelines in ADF	BICOE	Avoid partial ingestion.
31	Execute backout data tests for Oracle source	QA / BICOE	Run basic validations to ensure rollback integrity.
32	Notify MI users on rollback	BICOE	With estimated new timeline.
33	Close out backout ServiceNow tasks	PMO	Attach rollback validation proof.
--------------------------------
‚úÖ 1. Pre-Implementation Phase
üîπ BICOE Team
 Send communication to MI users on planned upgrade and data unavailability window.

 Announce dry run timeline to downstream teams, support, and stakeholders.

 Pause MI pipeline execution (ADF triggers or job disables).

 Deploy all updated ADF pipelines to production.

 Update ADF pipeline configuration to point to Prod Read Replica linked service.

 Ensure access to Prod Read Replica is available for all integration services and teams.

 Ensure Databricks production environment has required secrets, tokens, and libraries in place.

 Verify schema compatibility in production Read Replica.

 Review and finalize smoke test scripts.

 Confirm test data sufficiency in Read Replica for validation cases.

 Validate and document baseline metrics for downstream jobs (pre-upgrade).

üîπ AZ Infra Team
 Final verification of Read Replica availability.

 Confirm source switch readiness (Guidewire cloud source endpoint available).

 Prepare rollback/restore steps (snapshots or re-pointing non-cloud DB).

üîπ Data Engineering / MI
 Validate manual and automated validation scripts for key pipelines.

 Review and sign off test case coverage for post-load validation.

 Confirm data lineage documentation is current.

 Schedule checkpoint and validation calls during release window.

üîπ Change & Coordination
 Ensure CAB approval is in place for dry run.

 Setup communication bridge (MS Teams/Zoom) for release window.

 Assign owners for each checkpoint and validation task.

üöÄ 2. Implementation Phase
üîπ AZ Infra Team
 Initiate source switch from legacy Guidewire (Oracle) to Cloud Guidewire (Read Replica).

 Confirm successful connection via test query.

 Notify BICOE and Data Eng team to trigger data loads.

üîπ BICOE / Data Eng
 Manually trigger data pipelines to start ingestion from new Read Replica source.

 Monitor ADF pipeline execution, track failure/retries.

 Perform initial health check on ingestion success rate.

 Validate schema match on ingested data tables (sampled check).

üîé 3. Post-Implementation Testing
üîπ BICOE / Data Eng / QA
 Run smoke test scripts across PC, CC, BC datasets.

 Validate high-priority dashboards/MI reports reflect updated data.

 Validate at least one complete record from all major entities flows end-to-end.

 Check special character handling, decimals, and date formats.

 Monitor pipeline success for delta loads (if applicable).

 Validate no critical schema drift observed.

 Capture logs and metrics for defect triage.

üîπ Downstream Data Consumers (Marketing, SPV, etc.)
 Validate impact on Gold views, Silver layer, and key aggregations.

 Confirm no unexpected data breaks or delays.

 Apply temporary pause (if agreed) for SPV or sensitive downstream apps.

üìò 4. Post-Testing Activities
üîπ All Teams
 Review and sign off test summary reports.

 Capture known issues, accepted risks, and resolved defects.

 Notify stakeholders of successful validation.

 Finalize documentation (validation logs, screenshots, signoffs).

üîÅ 5. Backout Plan (if required)
üîπ AZ Infra / BICOE
 Revert source from Cloud Guidewire to legacy Oracle (non-cloud).

 Re-point ADF pipelines back to legacy DB linked service.

 Deploy previous pipeline versions (via CI/CD rollback or Git version).

 Re-enable MI jobs with Oracle source.

 Inform all stakeholders of rollback.

‚úÖ 6. Post-Backout Plan Testing
üîπ BICOE / QA / MI
 Run sanity checks to validate rollback success.

 Compare current data load with pre-dry-run baseline.

 Run sample reports and critical dashboards.

 Confirm recovery of SPV or paused downstream processes.

üì¶ 7. Closure
üîπ Change/Release Management
 Close ServiceNow change tasks.

 Archive logs, validation reports, and incident records.

 Conduct a dry run retrospective (lessons learned).

 Confirm readiness for actual go-live upgrade.

üìå Additional Key Inclusions
Test Summary Signoff:

 Signed by: BICOE, QA Lead, Downstream Consumers

 Summary includes defect list, resolved/accepted risks, test case coverage.

Access Checklist:

 Source Read Replica DB (Prod)

 ADF Prod Workspace

 Databricks Prod Workspace

 Monitoring dashboards (ADF/Log Analytics)

Checkpoints:

 T-2 hrs: Dry run readiness check

 T+0 hrs: Source switch checkpoint

 T+2 hrs: Ingestion completion validation

 T+6 hrs: Downstream validation checkpoint

 T+10 hrs: Final signoff checkpoint

Risks & Mitigation:

Schema drift handling not fully tested in prod ‚Äì Mitigation: enable alert rules, post-release monitoring

Delta load failure in test env ‚Äì Mitigation: validate in prod under monitored mode

Read Replica access delay ‚Äì Mitigation: validate access 24h in advance

Extension Plan:

 If any critical defect or block: 4-hour release window extension pre-approved

 Post 4-hour threshold: backout plan triggers automatically

----------------------------------------------------------------


Subject: Mandatory Process for Planned Leaves ‚Äì No Exceptions

Dear Team,

This is a reminder and directive regarding the process for managing planned leaves, as set by both Cognizant and our Client organization. Please read this carefully and ensure full adherence moving forward ‚Äî no exceptions.

üö® Why This Matters:
We‚Äôve had escalations recently due to last-minute or uninformed leave notifications. These not only impact client planning and delivery timelines but also put unfair workload pressure on peers. While emergencies are fully understood, planned leaves must never be communicated the day before or at the last moment. This creates operational and client trust issues and leads to unnecessary escalations.

Let me be clear: You are absolutely entitled to take your leaves ‚Äî that‚Äôs your earned benefit. The issue arises only when the leave is communicated late or not tracked properly, disrupting timelines and team balance.

‚úÖ Going forward, follow this process without exception:
1. Cognizant Leave Process:
Deva will continue sharing the leave tracker for the upcoming months. Update your planned leaves proactively.

If you're not currently on the tracker, please ask Deva to include you.

Apply the leave in the Cognizant system in advance and inform the team via email.

2. Client Leave Process:
Update the client-side leave tracker at least two weeks in advance.

This allows the PM to assess impact, assign temporary coverage, or adjust timelines early.

Set an Out of Office message, block your Outlook calendar, and notify all stakeholders you work closely with.

Everyone on the client side follows this standard ‚Äì we expect you to do the same.

If you‚Äôre unable to update the tracker or foresee any constraint, please inform me directly in advance so we can handle it appropriately.

Let‚Äôs avoid unnecessary escalations and ensure a smoother experience for everyone involved.

 Note:
Emergency leave is understandable‚Äîplease notify your reporting manager and the team at the earliest in such cases.

For onshore team members, planned leaves typically require replacement planning and client approval at least 2 months in advance.

Thanks for your cooperation,
