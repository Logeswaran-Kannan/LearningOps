import os
import pandas as pd
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, countDistinct, current_date

# Set the DBFS location where you want to save the profiling output
output_location = "/dbfs/path/to/output/"

# Read the CSV file containing the database and table names
csv_file_path = "/dbfs/path/to/repo_tables.csv"
df_tables = pd.read_csv(csv_file_path)

# Create a SparkSession
spark = SparkSession.builder.getOrCreate()

# Iterate over each row in the dataframe
for index, row in df_tables.iterrows():
    database_name = row['Database']
    table_name = row['Table']

    # Check if the table exists
    if spark.catalog._jcatalog.tableExists(database_name, table_name):
        # Get the column names from the table
        column_names = spark.catalog.listColumns(database_name, table_name)
        column_names = [col_name.name for col_name in column_names]

        # Perform data profiling using SQL
        df_profile = spark.sql(f"SELECT {', '.join(column_names)} FROM {database_name}.{table_name}")
        for column in column_names:
            distinct_values = df_profile.select(column).distinct().collect()
            distinct_count = len(distinct_values)
            total_count = df_profile.count()
            value_contribution = (distinct_count / total_count) * 100

            # Create a dataframe with profiling results
            profiling_data = pd.DataFrame({
                'schema': [database_name],
                'tablename': [table_name],
                'columnname': [column],
                'distinct value': [distinct_count],
                'value contribution in %': [value_contribution],
                'currentdate': [current_date()]
            })

            # Save the profiling results as a TXT file
            output_file_path = os.path.join(output_location, f"{database_name}_{table_name}_{column}.txt")
            profiling_data.to_csv(output_file_path, sep='\t', index=False, mode='overwrite')
    else:
        print(f"Table '{database_name}.{table_name}' not found.")

print("Data profiling completed.")
