# Databricks Notebook: PyTest Integration with Azure DevOps (Single Notebook)

# STEP 1: Install pytest from Volumes path
# Replace <catalog>, <schema>, <volume> with your actual values

%pip install /Volumes/<catalog>/<schema>/<volume>/pytest-7.4.0-py3-none-any.whl

# STEP 2: Create test directory and test file with both pass and fail cases

import os

# Use DBFS path to store test suite
test_dir = "/dbfs/tmp/test_suite"
os.makedirs(test_dir, exist_ok=True)

# Sample test cases
# Includes: Null check (fail), Duplicate check (fail), Simple pass

test_code = '''
import pandas as pd

def test_check_nulls():
    df = pd.DataFrame({
        "id": [1, 2, 3],
        "name": ["Alice", "Bob", None]  # Intentional null
    })
    assert df["name"].isnull().sum() == 0, "Null value found in 'name' column"  # FAIL

def test_check_duplicates():
    df = pd.DataFrame({
        "id": [1, 2, 2, 3],
        "name": ["Alice", "Bob", "Bob", "Charlie"]
    })
    assert df.duplicated(subset=['id']).sum() == 0, "Duplicate IDs found"  # FAIL

def test_simple_pass():
    assert 1 + 1 == 2  # PASS
'''

# Write test file
with open(f"{test_dir}/test_sample.py", "w") as f:
    f.write(test_code)

# STEP 3: Run PyTest and generate JUnit XML result in DBFS

!pytest /dbfs/tmp/test_suite --junitxml=/dbfs/tmp/test_results/results.xml

# STEP 4: (Info) Path to output file for Azure DevOps
print("Test results saved to: dbfs:/tmp/test_results/results.xml")
