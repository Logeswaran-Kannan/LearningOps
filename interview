import os
from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Initialize SparkSession
spark = SparkSession.builder.getOrCreate()

# Load the existing table
existing_table = spark.table("your_existing_table_name")

# Filter files to be deleted
files_to_delete = existing_table.filter(col("deletable") == "deletable").select("path").collect()

# Delete files
for row in files_to_delete:
    file_path = row.path
    try:
        # Delete the file
        dbfs_path = "dbfs:" + file_path
        dbutils.fs.rm(dbfs_path, recurse=True)
        
        # Update the existing table with the "deleted" value
        existing_table = existing_table.withColumn("deletable", \
                                                   when(col("path") == file_path, "deleted").otherwise(col("deletable")))
        
    except Exception as e:
        print(f"Failed to delete file {file_path}: {str(e)}")

# Update the existing table with the changes
existing_table.write.mode("overwrite").saveAsTable("your_existing_table_name")
