from pyspark.sql import SparkSession

# Create SparkSession
spark = SparkSession.builder \
    .appName("TableColumnList") \
    .getOrCreate()

# Set the database name
database_name = "<your_database_name>"

# Get the table names in the database
table_names = spark.catalog.listTables(database_name)

# Initialize an empty dictionary to store the table names and their column lists
table_columns = {}

# Iterate over the table names
for table in table_names:
    table_name = table.name

    # Exclude tables starting with "__app%"
    if not table_name.startswith("__app%"):
        # Get the table schema
        table_schema = spark.table(f"{database_name}.{table_name}").schema

        # Get the column names excluding "__START_AT" and "__END_AT"
        column_list = [column.name for column in table_schema
                       if column.name not in ["__START_AT", "__END_AT"]]

        # Add the table name and column list to the dictionary
        table_columns[table_name] = column_list

# Print the table names and their column lists
for table, columns in table_columns.items():
    print(f"Table: {table}")
    print(f"Columns: {columns}\n")

# Stop the SparkSession
spark.stop()
