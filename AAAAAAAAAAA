Hi Steve,

Agree with Arindom’s explanation — since we are using standard compression/decompression libraries and this approach is already proven across the wider project, we don’t see any risk of data loss. From our side, we are comfortable skipping this test.

The only point to confirm is whether all DE feeds are expected to be compressed, as we’ve seen cases like Watchlist where compression wasn’t applied. But overall, the risk is minimal.

On the size limits, Databricks can handle messages up to ~16 MB, and our largest payloads are only 200–300 KB, so we are well within safe limits.

Thanks,
Logeswaran
