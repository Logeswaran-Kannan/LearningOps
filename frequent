# Import required libraries
from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from databricks import koalas as ks
import databricks.automl

# Initialize Spark session
spark = SparkSession.builder.appName("ExploratoryDataAnalysis").getOrCreate()

# Replace 'database_name' with your actual database name
database_name = "your_database_name"

# Replace 'table_names' with a list of table names you want to analyze
table_names = ["table1", "table2", "table3"]

# Load tables into DataFrames
dataframes = {}
for table in table_names:
    dataframes[table] = spark.table(f"{database_name}.{table}")

# Perform EDA
eda_results = {}
for table, df in dataframes.items():
    eda_results[table] = df.describe().toPandas()

# Convert EDA results to HTML
eda_html = ""
for table, eda_df in eda_results.items():
    eda_html += f"<h2>{table}</h2>"
    eda_html += eda_df.to_html()

# Display HTML using Databricks AutoML libraries
dbutils.automl.displayHTML(eda_html)
