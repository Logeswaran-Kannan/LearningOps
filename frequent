# Import necessary libraries
from pyspark.sql import SparkSession
from pyspark.sql.functions import col
import pandas as pd

# Initialize Spark session
spark = SparkSession.builder.appName("EDA").getOrCreate()

# Define the database and table names
database_name = "your_database"
table_name = "your_table"

# Read data from the table
data = spark.sql(f"SELECT * FROM {database_name}.{table_name}")

# Perform basic EDA
summary = data.describe().toPandas()

# Calculate missing values
missing_values = data.select([col(c).alias(c, str(int(col(c).isNull().mean() * 100)) + '% missing') for c in data.columns])

# Calculate data types
data_types = pd.DataFrame(data.dtypes, columns=["column", "data_type"])

# Convert the EDA results to HTML format
eda_html = """
<!DOCTYPE html>
<html>
<head>
  <style>
    table {{
      border-collapse: collapse;
      width: 50%;
      margin: auto;
    }}
    th, td {{
      border: 1px solid black;
      padding: 8px;
      text-align: left;
    }}
  </style>
</head>
<body>
  <h2>Exploratory Data Analysis</h2>
  <h3>Summary Statistics</h3>
  {}
  <h3>Missing Values</h3>
  {}
  <h3>Data Types</h3>
  {}
</body>
</html>
""".format(summary.to_html(index=False), missing_values.toPandas().to_html(index=False), data_types.to_html(index=False))

# Save the HTML content to a Databricks notebook cell
displayHTML(eda_html)
