from flask import Flask, render_template, request
import os
from datetime import datetime, timedelta
from pyspark.sql import SparkSession

app = Flask(__name__)

# Connect to Databricks cluster
spark = SparkSession.builder \
    .appName("DBFS File Stats") \
    .getOrCreate()

# Get current date
current_date = datetime.now()

# Function to check if a file's last update date is 2 years from the current date
def is_delete_ready(last_update_date):
    return (current_date - last_update_date).days >= 365 * 2

# Function to retrieve file stats and create a DataFrame
def get_file_stats(file_path):
    try:
        file_stats = os.stat(file_path)
        file_name = os.path.basename(file_path)
        file_size = file_stats.st_size
        file_creation_date = datetime.fromtimestamp(file_stats.st_ctime)
        file_last_update_date = datetime.fromtimestamp(file_stats.st_mtime)
        file_created_by = file_stats.st_uid
        delete_ready = is_delete_ready(file_last_update_date)
        
        return (file_name, file_size, file_path, file_creation_date, file_last_update_date, file_created_by, delete_ready)
    
    except Exception as e:
        print(f"Error retrieving stats for file: {file_path}")
        print(str(e))
        return None

# Recursive function to traverse the directory structure and retrieve file stats
def get_files_info(directory):
    file_stats_list = []
    
    for root, dirs, files in os.walk(directory):
        for file in files:
            file_path = os.path.join(root, file)
            if os.path.isfile(file_path):
                file_stats = get_file_stats(file_path)
                if file_stats is not None:
                    file_stats_list.append(file_stats)
    
    return file_stats_list

# Home route
@app.route('/', methods=['GET', 'POST'])
def home():
    if request.method == 'POST':
        # Get the DBFS path from the user
        dbfs_path = request.form['dbfs_path']
        
        # Get file stats for the DBFS path and its child paths
        file_stats_list = get_files_info(dbfs_path)

        # Convert the list to a DataFrame
        file_stats_df = spark.createDataFrame(file_stats_list, ["name", "size", "path", "creation_date", "last_update_date", "created_by", "delete_ready"])

        # Temporary table name
        temp_table_name = "file_stats_temp"

        # Register DataFrame as a temporary table
        file_stats_df.createOrReplaceTempView(temp_table_name)

        # Query to show the file stats and the creator's username
        query = f"SELECT name, size, path, creation_date, last_update_date, delete_ready, username(created_by) as creator_username FROM {temp_table_name}"

        # Run the query and retrieve the results
        results = spark.sql(query).collect()

        # Render the template with the results
        return render_template('results.html', results=results)
    
    return render_template('index.html')

if __name__ == '__main__':
    app.run(debug=True)
