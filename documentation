import os
from pyspark.sql import SparkSession
from pyspark.sql.functions import lit, current_timestamp

# Create a SparkSession
spark = SparkSession.builder \
    .appName("FileStats") \
    .getOrCreate()

def collect_file_stats(dbfs_path):
    # Create an empty DataFrame with the required columns
    file_stats_df = spark.createDataFrame([], 
                    "name STRING, size LONG, path STRING, creation_date TIMESTAMP, last_update_date TIMESTAMP, del_status STRING, del_date TIMESTAMP, recommendation STRING")
    
    # Recursive function to collect file stats from a given path
    def collect_stats_recursively(path):
        # Get the list of files and directories in the current path
        files = dbutils.fs.ls(path)
        
        for file in files:
            if file.isDir():
                # If it's a directory, recursively call the function
                collect_stats_recursively(file.path)
            else:
                # If it's a file, collect its stats
                name = file.name
                size = file.size
                path = file.path
                creation_date = file.creationTime
                last_update_date = file.modificationTime
                
                # Create a new row with the file stats
                new_row = spark.createDataFrame([(name, size, path, creation_date, last_update_date, "", None, "")],
                                                "name STRING, size LONG, path STRING, creation_date TIMESTAMP, last_update_date TIMESTAMP, del_status STRING, del_date TIMESTAMP, recommendation STRING")
                
                # Append the new row to the DataFrame
                file_stats_df.union(new_row)

    # Call the recursive function to collect file stats from the given DBFS path
    collect_stats_recursively(dbfs_path)
    
    # Add the current timestamp to the del_date column for all rows
    file_stats_df = file_stats_df.withColumn("del_date", current_timestamp())
    
    # Write the DataFrame to a permanent table in the default schema
    file_stats_df.write.mode("append").saveAsTable("default.file_stats")
    
    # Show the final result in table format
    file_stats_df.show()

# Example usage: collect_file_stats("/dbfs/path/to/directory")
