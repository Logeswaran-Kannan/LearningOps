from pyspark.sql import SparkSession
from pyspark.sql.functions import col, lit

# Initialize SparkSession
spark = SparkSession.builder \
    .appName("Column-level Data Comparison") \
    .getOrCreate()

# Load CSV file into a DataFrame and create the first table
csv_file_path = "/dbfs/path/to/csv/file.csv"
first_table_name = "table_1"

# Use try-except block to handle exception if the table already exists
try:
    df = spark.read.csv(csv_file_path, header=True, inferSchema=True)
    df.write.mode("overwrite").saveAsTable(first_table_name)
except:
    print(f"Table '{first_table_name}' already exists. Skipping table creation.")

# Define the list of columns to compare
columns_to_compare = ["column1", "column2", "column3"]  # Add your column names here

# Load the second table from the database
second_table_name = "table_2"
second_table_df = spark.table(second_table_name)

# Filter records in the second table that exist in the first table based on policy_reference
distinct_policy_references = df.select("policy_reference").distinct()
filtered_second_table_df = second_table_df.join(
    distinct_policy_references, on="policy_reference", how="inner"
)

# Perform minus operation between the two tables for the specified columns
comparison_results = df.alias("df1").join(
    filtered_second_table_df.alias("df2"),
    on=["policy_reference"],
    how="left_anti"
)

# Create a DataFrame to hold the comparison results
results_df = comparison_results.select("policy_reference")

# Compare each column and add the result to the results DataFrame
for column in columns_to_compare:
    result_column = f"{column}_result"
    result_value = f"{column}_value"
    
    results_df = results_df.withColumn(
        result_column,
        (col(f"df1.{column}") == col(f"df2.{column}")).cast("string")
    ).withColumn(
        result_value,
        lit(f"df1.{column} = {{df1.{column}}}, df2.{column} = {{df2.{column}}}")
    )

# Show the results DataFrame with comparison status and values
results_df.show()

# Save the results DataFrame as an output table
output_table_name = "comparison_output"
results_df.write.mode("overwrite").saveAsTable(output_table_name)

# Stop the SparkSession
spark.stop()
