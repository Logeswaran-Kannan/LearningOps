from pyspark.sql import SparkSession
from pyspark.sql.functions import col, lit, expr

# Initialize the SparkSession
spark = SparkSession.builder.appName("Data Comparison").getOrCreate()

# Step 1: Create the first table based on a CSV file in DBFS
csv_file_path = "/dbfs/path/to/your/csv/file.csv"
table_name = "first_table"

df = spark.read.option("header", "true").csv(csv_file_path)
df.createOrReplaceTempView(table_name)

# Step 2: Check if the table already exists and overwrite if required
overwrite_existing = True

if spark.catalog.tableExists(table_name) and overwrite_existing:
    spark.sql(f"DROP TABLE IF EXISTS {table_name}")
    df.write.saveAsTable(table_name)
elif not spark.catalog.tableExists(table_name):
    df.write.saveAsTable(table_name)

# Step 3: Create the second table with distinct policy_reference values
second_table_name = "second_table"
distinct_df = spark.sql(f"SELECT DISTINCT policy_reference FROM {table_name}")
distinct_df.createOrReplaceTempView(second_table_name)

# Define the list of columns for data comparison
columns_to_compare = ["column1", "column2", "column3"]

# Step 4: Define a function to perform data comparison for the specified columns
def compare_data(policy_reference, columns_to_compare):
    df1 = spark.sql(f"SELECT * FROM {table_name} WHERE policy_reference = '{policy_reference}'")
    df2 = spark.sql(f"SELECT * FROM {table_name} WHERE policy_reference = '{policy_reference}'")

    comparison_results = []
    for column in columns_to_compare:
        df1_value = df1.select(column).collect()[0][0]
        df2_value = df2.select(column).collect()[0][0]
        status = "Pass" if df1_value == df2_value else "Fail"
        comparison_results.append((column, df1_value, df2_value, status))

    return comparison_results

# Step 5: Perform data comparison and capture the results in an output table
output_table_name = "comparison_output_table"

# Create a list to store the results for all policy_references
all_comparison_results = []

# Loop through each distinct policy_reference and compare the data
for row in distinct_df.collect():
    policy_reference = row[0]
    comparison_results = compare_data(policy_reference, columns_to_compare)
    all_comparison_results.extend(comparison_results)

# Create a DataFrame from the comparison results
output_df = spark.createDataFrame(all_comparison_results, ["column", "df1_value", "df2_value", "status"])

# Save the output DataFrame as a table
output_df.write.saveAsTable(output_table_name)

# Show the comparison results
output_df.show()

if spark.catalog.tableExists(output_table_name) and overwrite_existing:
    spark.sql(f"DROP TABLE IF EXISTS {output_table_name}")

# Save the output DataFrame as a table
output_df.write.mode("overwrite").saveAsTable(output_table_name)
