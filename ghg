from pyspark.sql import SparkSession
from pyspark.sql.functions import *
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from IPython.display import HTML

# Initialize Spark session
spark = SparkSession.builder.appName("ExploratoryDataAnalysis").getOrCreate()

# Load input CSV containing DLT view names
input_csv_path = "dbfs:/path/to/input.csv"  # Update with the actual DBFS path
input_df = spark.read.option("header", "true").csv(input_csv_path)
dlt_view_names = input_df.select("DLTViewName").rdd.flatMap(lambda x: x).collect()

# Output DBFS path for saving HTML files
output_dbfs_path = "dbfs:/path/to/output_folder/"  # Update with the actual DBFS path

# Function to generate EDA HTML report for a DLT view
def generate_eda_report(dlt_view_name):
    # Load data from DLT view
    data = spark.sql(f"SELECT * FROM {dlt_view_name}")

    # EDA code (similar to the previous example)
    # ...

    # Convert summary, missing_values, and correlation_matrix to HTML
    # ...

    # Combine HTML components
    eda_report_html = f"""
    <html>
    <head>
    <style>
    {correlation_matrix_html}
    </style>
    </head>
    <body>
    <h2>Exploratory Data Analysis Report for {dlt_view_name}</h2>
    <h3>Summary Statistics</h3>
    {summary_html}
    <h3>Missing Values</h3>
    {missing_values_html}
    <h3>Correlation Matrix</h3>
    {correlation_matrix_html}
    </body>
    </html>
    """

    # Save HTML report to output DBFS path
    output_file_path = f"{output_dbfs_path}/{dlt_view_name}_eda_report.html"
    with open(output_file_path, "w") as html_file:
        html_file.write(eda_report_html)

# Generate EDA reports and save HTML files for each DLT view
for dlt_view_name in dlt_view_names:
    generate_eda_report(dlt_view_name)

# Cleanup: Delete existing output files
dbutils.fs.rm(output_dbfs_path, True)

# Display completion message
print("EDA reports generated and HTML files saved.")
