from pyspark.sql import SparkSession

# Initialize Spark session
spark = SparkSession.builder \
    .appName("DataComparison") \
    .getOrCreate()

# Define the source and destination databases and tables
source_database = "source_db"
destination_database = "destination_db"
sample_size = 50  # Number of sample records to compare

# List tables in the source database and filter out tables to exclude
source_tables = spark.sql(f"SHOW TABLES IN {source_database}").filter(
    ~col("tableName").startswith("__apply") &
    ~col("tableName").endswith("__ghg")
)

for row in source_tables.collect():
    table_name = row["tableName"]

    # Skip excluded columns
    source_df = spark.sql(f"SELECT * FROM {source_database}.{table_name}").drop("source_system", "valid_from_dt")
    
    try:
        # Load the destination table
        destination_df = spark.sql(f"SELECT * FROM {destination_database}.{table_name}").drop("source_system", "valid_from_dt")

        # Take a sample from both source and destination tables
        source_sample = source_df.sample(False, sample_size / source_df.count())
        destination_sample = destination_df.sample(False, sample_size / destination_df.count())

        # Compare the data
        if source_sample.subtract(destination_sample).count() == 0 and destination_sample.subtract(source_sample).count() == 0:
            print(f"Table '{table_name}' data matches between source and destination databases.")
        else:
            print(f"Table '{table_name}' data does not match between source and destination databases.")

    except Exception as e:
        print(f"Table '{table_name}' missing in destination database. Error: {str(e)}")

# Stop the Spark session
spark.stop()
