from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Create a Spark session
spark = SparkSession.builder.appName("DataComparison").getOrCreate()

# Define your source and destination databases
source_database_name = "your_source_database"
destination_database_name = "your_destination_database"

# Function to get table names from a database excluding '__apply' and '__ghg' tables
def get_table_names(database_name):
    tables = spark.sql(f"SHOW TABLES IN {database_name}").toPandas()
    return tables[~tables.tableName.str.startswith("__apply") & ~tables.tableName.str.endswith("__ghg")]

# Get table names from source and destination databases
source_tables = get_table_names(source_database_name)
destination_tables = get_table_names(destination_database_name)

# Define the columns to exclude
excluded_columns = ['source_system', 'valid_from_dt']

# Create a temporary DataFrame to store the comparison results
comparison_results = []

# Compare data between source and destination databases
for table_row in source_tables.itertuples():
    table_name = table_row.tableName
    
    # Check if the table exists in the destination database
    if table_name in destination_tables['tableName'].values:
        # Get the list of columns for the current table, excluding the excluded columns
        columns = [col_name for col_name in spark.sql(f"DESCRIBE {source_database_name}.{table_name}").select('col_name').rdd.flatMap(lambda x: x).collect() if col_name not in excluded_columns]
        
        # Take a sample of 50 records from the source table
        source_sample = spark.sql(f"SELECT {', '.join(columns)} FROM {source_database_name}.{table_name}").sample(False, 0.01)
        
        # Take the same sample from the destination table
        destination_sample = spark.sql(f"SELECT {', '.join(columns)} FROM {destination_database_name}.{table_name}").sample(False, 0.01)
        
        # Compare the samples
        is_equal = source_sample.exceptAll(destination_sample).isEmpty()
        
        status = "Match" if is_equal else "Mismatch"
        comparison_results.append((table_name, status))
    else:
        comparison_results.append((table_name, "Missing in Destination"))

# Add missing tables from destination to comparison results
for table_row in destination_tables.itertuples():
    table_name = table_row.tableName
    if table_name not in source_tables['tableName'].values:
        comparison_results.append((table_name, "Missing in Source"))

# Create a DataFrame from the results
comparison_df = spark.createDataFrame(comparison_results, ["Table_Name", "Status"])

# Show the comparison results
comparison_df.show()

# Stop the Spark session
spark.stop()
