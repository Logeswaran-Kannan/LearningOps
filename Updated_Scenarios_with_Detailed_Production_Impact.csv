ID / Name,Scenario Description,Simulation Method,Expected Outcome,Actual Outcome,Comments,Checkpoint with Development Team,Predicted Impact if Occurs in Production
Source System Issues_001,Source data is unavailable,,,,,,"The process will not fail if no data is available in the source (e.g., weekends) and there is no network-related failure. The workflow runs as expected, logging zero counts. Only if the expectation is unmet due to a genuine error would failure occur."
Source System Issues_002,Source data is partially available,,,,,,"If only partial data is available, the ingestion process will continue loading available records. This may cause downstream inconsistencies but does not cause the workflow to fail. The missing data will be picked up in the next scheduled run. This is expected behavior."
Connectivity_001,Network is down,,,,,,"During network failures, the system retries up to 3 times before failing. If the issue persists, manual intervention by the application support team is needed. If it occurs on weekends, the missed data is picked up during the next load cycle."
Connectivity_002,Invalid credentials,,,,,,"If thereâ€™s a license or credential issue (e.g., expired service account password), the process fails and sends alerts to the application support team, who then work to restore credentials. Expected behavior."
Schema_Mismatches_001,New columns added in source,,,,,,New columns are not automatically ingested due to metadata control in the read replica process. Manual intervention is needed to include new columns in ODS. Schema drift automation will be enabled via CDA in the future.
Schema_Mismatches_002,Expected columns are missing,,,,,,"If a previously existing column is missing in the source but not announced, the ingestion process fails. However, if source changes are communicated, the column remains in Databricks ODS but loads NULLs. Both are controlled and expected behaviors."
Schema_Mismatches_003,Data type mismatch,,,,,,"If the data type changes to an incompatible type (e.g., boolean to date), the process fails. If changes are cast-compatible (e.g., double to int), the process proceeds. Automation and BAU notification processes are needed to track such changes."
Schema_Mismatches_004,Column order changed,,,,,,"Column order or case sensitivity does not affect the workflow. Column mapping is one-to-one and all names are normalized to lowercase, so ingestion proceeds smoothly."
System_001,Azure storage write failure,,,,,,"If Azure storage is unavailable, the process fails. Once restored, either a manual reprocessing or the next scheduled load resumes from the last successful point."
System_002,Databricks cluster down mid-ingestion,,,,,,"If the Databricks cluster goes down mid-process, the job fails. On service restoration, it either requires manual reprocessing or resumes automatically in the next load window."
System_003,Insufficient compute,,,,,,"In case of limited compute, autoscaling supports processing for up to 7 days. The process only fails if no nodes are available at all. Application support monitors performance to preempt issues."
System_004,Re-ingestion after failure,,,,,,The restore process resumes using the SQL Server max process time checkpoint. Deduplication is built in to prevent duplicate loads. The process continues without failure even if duplicates are detected.
