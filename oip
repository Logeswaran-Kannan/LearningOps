
    # Loop through each column and perform data profiling
    for column_name in table_df.columns:
        # Count of distinct values
        distinct_count = table_df.select(countDistinct(col(column_name))).collect()[0][0]

        # Count of null values
        null_count = table_df.select(count(when(col(column_name).isNull(), True))).collect()[0][0]

        # Null percentage
        total_rows = table_df.count()
        null_percentage = (null_count / total_rows) * 100

        # Average length (for StringType columns)
        if isinstance(table_df.schema[column_name].dataType, StringType):
            avg_length = table_df.select(avg(length(col(column_name)))).collect()[0][0]
        else:
            avg_length = None

        # Data type
        data_type = table_df.schema[column_name].dataType

        # Minimum and Maximum values (for numeric columns)
        if isinstance(data_type, (int, float)):
            min_value = table_df.select(min(col(column_name))).collect()[0][0]
            max_value = table_df.select(max(col(column_name))).collect()[0][0]
        else:
            min_value = None
            max_value = None

        # Most common value
        most_common_value = None
        if not table_df.isEmpty():
            most_common_value = table_df.groupBy(column_name).agg(count(lit(1)).alias("count")) \
                .orderBy(col("count").desc()).first()[column_name]

        # Append the profiling results to the list
        profiling_results.append((table_name, column_name, distinct_count, null_count, null_percentage,
                                  avg_length, data_type, min_value, max_value, most_common_value))

    return profiling_results
