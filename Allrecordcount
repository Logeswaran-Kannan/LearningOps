from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count, when, lit, expr

# Initialize Spark Session
spark = SparkSession.builder.appName("DataMigrationValidation").enableHiveSupport().getOrCreate()

# Define Source and Target Catalogs and Databases
source_catalog = "ods"
target_catalog = "ods_views"
output_catalog = "core_tst_sys9"
output_table = "default.validation_results"

# Fetch Source Table List
source_tables = [row["tableName"] for row in spark.sql(f"SHOW TABLES IN {source_catalog}").collect()]

def get_table_schema(database, table_name):
    """Fetches table schema as a set of column names."""
    return set([col["col_name"] for col in spark.sql(f"DESCRIBE {database}.{table_name}").collect()])

def validate_table(src_table, tgt_table):
    """Validates source and target tables and returns a result row."""
    try:
        src_df = spark.table(f"{source_catalog}.{src_table}")
        tgt_df = spark.table(f"{target_catalog}.{tgt_table}")

        # Fetch DDL Schema
        src_schema = get_table_schema(source_catalog, src_table)
        tgt_schema = get_table_schema(target_catalog, tgt_table)

        # Identify missing columns
        src_missing_cols = list(tgt_schema - src_schema)
        tgt_missing_cols = list(src_schema - tgt_schema)

        # Align schema by dropping extra columns
        common_cols = list(src_schema & tgt_schema)
        src_df = src_df.select(common_cols)
        tgt_df = tgt_df.select(common_cols)

        # Count comparison
        src_count = src_df.count()
        tgt_count = tgt_df.count()

        # Data comparison
        data_mismatch_count = src_df.subtract(tgt_df).count()
        rev_data_mismatch_count = tgt_df.subtract(src_df).count()

        # Null Count Comparison
        null_count_diff_cols = []
        for col_name in common_cols:
            src_nulls = src_df.select(count(when(col(col_name).isNull(), col_name))).collect()[0][0]
            tgt_nulls = tgt_df.select(count(when(col(col_name).isNull(), col_name))).collect()[0][0]
            if src_nulls != tgt_nulls:
                null_count_diff_cols.append(col_name)

        # Determine Status and Comments
        if src_schema == tgt_schema and src_count == tgt_count and data_mismatch_count == 0 and rev_data_mismatch_count == 0 and not null_count_diff_cols:
            status, comment = "PASS", "All tests passed"
        elif src_schema != tgt_schema:
            status, comment = "FAIL", "DDL Mismatch"
        elif src_count != tgt_count:
            status, comment = "FAIL", "Count Mismatch"
        elif data_mismatch_count > 0 or rev_data_mismatch_count > 0:
            status, comment = "FAIL", "Data Mismatch"
        elif null_count_diff_cols:
            status, comment = "FAIL", "Null Count Mismatch"
        else:
            status, comment = "FAIL", "Unknown Error"

        # Prepare Result Row
        result_row = [(src_table, source_catalog, target_catalog, str(src_missing_cols), str(tgt_missing_cols),
                      src_count, tgt_count, data_mismatch_count, rev_data_mismatch_count,
                      str(null_count_diff_cols), "", status, comment)]

        return spark.createDataFrame(result_row, ["table_name", "src_database", "target_database", "src_vs_target_ddl_missing", "target_vs_src_ddl_missing",
                                                  "src_count", "target_count", "src_vs_target_data_diff", "target_vs_src_data_diff",
                                                  "null_count_differences", "data_mismatch_columns", "status", "comment"])
    except Exception as e:
        # Handle cases where table does not exist
        error_row = [(src_table, source_catalog, target_catalog, "", "", 0, 0, 0, 0, "", "", "FAIL", f"Error: {str(e)}")]
        return spark.createDataFrame(error_row, ["table_name", "src_database", "target_database", "src_vs_target_ddl_missing", "target_vs_src_ddl_missing",
                                                  "src_count", "target_count", "src_vs_target_data_diff", "target_vs_src_data_diff",
                                                  "null_count_differences", "data_mismatch_columns", "status", "comment"])

# Iterate over tables and validate
final_results = None
for src_table in source_tables:
    tgt_table = f"vm_{src_table}"
    result_df = validate_table(src_table, tgt_table)
    final_results = result_df if final_results is None else final_results.union(result_df)

# Write results to output table with version history
final_results.withColumn("execution_time", expr("current_timestamp()"))
final_results.write.mode("append").saveAsTable(f"{output_catalog}.{output_table}")

print("Validation completed and results stored successfully.")
