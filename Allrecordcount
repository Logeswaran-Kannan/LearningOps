from pyspark.sql import SparkSession

# Initialize Spark session
spark = SparkSession.builder.getOrCreate()

# Define catalog and database
catalog = "core_tst"
database = "ODS"

# Set catalog and database
spark.catalog.setCurrentCatalog(catalog)
spark.catalog.setCurrentDatabase(database)

# Efficiently list all table names
table_names = [table.name for table in spark.catalog.listTables(database)]

print(f"Total tables in {catalog}.{database}: {len(table_names)}")
for name in table_names:
    print(name)
