from pyspark.sql import SparkSession

# Initialize Spark session
spark = SparkSession.builder.getOrCreate()

# Define catalog and database
catalog = "core_preprod"
database = "default"
full_table_name = f"{catalog}.{database}.sample_access_check"

# Create a small DataFrame
data = [("Alice", 1), ("Bob", 2)]
columns = ["name", "id"]
df = spark.createDataFrame(data, columns)

# Try writing the DataFrame as a Delta table
try:
    df.write.mode("overwrite").format("delta").saveAsTable(full_table_name)
    print(f"✅ Table created successfully: {full_table_name}")
except Exception as e:
    print(f"❌ Failed to create table: {e}")
