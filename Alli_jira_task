🔍 Test Scenario ID: EH-BR-01 – Message Receipt Validation
🔹 Purpose
This scenario ensures that all messages generated by the MQS source systems (e.g., Athena) and delivered via MuleSoft to Azure Event Hub are fully received and ingested into the Bronze (Landed) table without data loss. It is the foundational test to confirm the successful initiation of the ingestion pipeline and the fidelity of raw data movement.

🔹 Scope and Components Involved
Source Systems: Athena/CRS (origin of MQS messages)

Integration Layer: MuleSoft (manages outbound traffic to Event Hub)

Streaming Layer: Azure Event Hub

Ingestion Layer: Databricks DLT pipeline (streaming from Event Hub)

Storage Layer: Bronze Landed Table (raw JSON with metadata)

🔹 Key Validation Objectives
Confirm all messages emitted by the source are persisted in the Bronze layer.

Validate presence of ingestion metadata (message_id, _ingest_time, event_type, etc.).

Ensure no data loss at stream handoff or during landing.

🧪 Testing Options & Analysis
✅ Option 1: Source (Athena/Mule) vs. Bronze Count Comparison
Approach: Use outbound message logs from Mule or storage (e.g., CosmosDB) to extract expected message count and identifiers. Match against records in the Bronze table.

Feasibility: Conditional — depends on availability and access to detailed logs or DBs.

Risks:

Incomplete or rotated logs may prevent accurate trace.

Retry mechanisms in Mule can lead to inflated counts if not deduplicated.

Complex access permissions may hinder real-time validation.

✅ Option 2: Azure Event Hub vs. Bronze Table Count
Approach: Use Azure Event Hub diagnostics, metrics, or monitoring dashboard to retrieve the number of messages emitted in a given interval. Compare against the landed message count in the Bronze table.

Feasibility: High — native support via Azure Monitor and metrics.

Risks:

Diagnostic metrics are aggregated and not message-specific.

Timing windows between EventHub and Bronze must be strictly aligned.

Dropped messages (if any) require offset gap analysis to detect.

✅ Option 3: Known Payload Test
Approach: Inject a known batch of test messages (e.g., 100 quote requests with traceable quote_ids). Validate the exact same number appear in Bronze.

Feasibility: High — preferred for controlled environments.

Risks:

Not suitable in production; requires isolated environment.

Test data must be crafted carefully to avoid contamination of analytics.

Doesn't reveal random drops during real-time spikes or failures.

🧾 Validation Scope Clarification
Not included here:

Schema conformity checks (EH-BR-02) will validate structure and type.

Null/corrupted message handling (EH-BR-04) is validated separately.

Deduplication logic (EH-BR-05) tested in specific scenario.

Traceability from Bronze → Silver (BR-SL-07, DQ-09) will be tested during downstream lineage validation.

✅ Success Criteria
Count of records in Bronze table = message count from source/EventHub (for the test window).

Metadata like _ingest_time, eventhub_enqueued_time, message_id, event_type is present and accurate.

No evidence of dropped, duplicated, or delayed records.

If string hash is applied, it's populated correctly (where applicable).

🗂 Mapped Data Quality Requirements
DQ Ref	Description
RL DQ01 – Accuracy	Ensures the raw payloads received in Bronze match the original source messages.
RL DQ03 – Completeness	Confirms no messages are missing or dropped during ingestion.
RL DQ09 – Traceability	Validates that metadata like message_id and timestamps are present for lineage tracking.

Note: Full traceability across Bronze → Silver → Gold is handled in BR-SL-07 and DQ-09-01/02.

Let me know if you want this formatted in your test case Excel or Word template next.
