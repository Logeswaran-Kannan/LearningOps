from pyspark.sql import SparkSession
from pyspark.sql.functions import col, when
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType
from concurrent.futures import ThreadPoolExecutor

# Initialize Spark session
spark = SparkSession.builder.appName("AutomatedValidation").getOrCreate()

# Catalog and database details
source_catalog = "core_tst_sys9"
source_db = "rr_source"
target_catalog = "core_tst_std001"
target_db = "ods"

# Table names to process
table_names = ["ptable1", "btable2", "ctable3"]

# Date filter
filter_start = '2025-05-12T00:00:01.0025+00:00'
filter_end = '2025-05-13T00:00:01.0025+00:00'

def convert_boolean_columns(df):
    converted_cols = []
    for column in df.columns:
        unique_vals = df.select(column).distinct().limit(100).rdd.flatMap(lambda x: x).collect()
        string_vals = set(map(lambda x: str(x).lower() if x is not None else "null", unique_vals))
        if string_vals.issubset({"t", "f", "null"}):
            df = df.withColumn(column, when(col(column).isNull(), 0)
                                       .when(col(column) == "t", 1)
                                       .when(col(column) == "f", 0)
                                       .otherwise(0))
            converted_cols.append(column)
    return df, converted_cols

# Update comparison logic to remove limit(1)
def compare_dataframes(source_comp_df, target_comp_df):
    source_only = source_comp_df.subtract(target_comp_df).count()
    target_only = target_comp_df.subtract(source_comp_df).count()
    return source_only, target_only

# Convert decimal columns to double in target DataFrame

def normalize_target_decimal_to_double(target_df):
    for column, dtype in target_df.dtypes:
        if dtype.startswith("decimal"):
            target_df = target_df.withColumn(column, col(column).cast("double"))
    return target_df

# Identify mismatched columns

def get_mismatched_columns(df1, df2, columns):
    mismatched = []
    for col_name in columns:
        diff_count = df1.select(col_name).subtract(df2.select(col_name)).count()
        reverse_diff_count = df2.select(col_name).subtract(df1.select(col_name)).count()
        if diff_count > 0 or reverse_diff_count > 0:
            mismatched.append(col_name)
    return mismatched
