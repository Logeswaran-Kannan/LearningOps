from pyspark.sql import SparkSession

# Start Spark session
spark = SparkSession.builder \
    .appName("CatalogueTableCounts") \
    .enableHiveSupport() \
    .getOrCreate()

# Function to list databases, tables, and row counts
def get_table_counts():
    results = []
    databases = [db.name for db in spark.catalog.listDatabases()]

    for db in databases:
        tables = spark.catalog.listTables(db)
        for table in tables:
            table_name = table.name
            full_table_name = f"{db}.{table_name}"
            try:
                count = spark.table(full_table_name).count()
                results.append((db, table_name, count))
            except Exception as e:
                results.append((db, table_name, f"Error: {str(e)}"))

    return results

# Run the function and show results
table_counts = get_table_counts()
for db, table, count in table_counts:
    print(f"Database: {db}, Table: {table}, Row Count: {count}")
