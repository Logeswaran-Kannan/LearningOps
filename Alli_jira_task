import requests
import pandas as pd

# Token and URL Setup
token = "test"
url = "https://adb-67779643136828772.12.azuredatabricks.net/api/2.0/lineage-tracking/column-lineage"
headers = {
    "Authorization": f"Bearer {token}",
    "Content-Type": "application/json"
}

# Load input data from CSV in DBFS
input_csv_path = "/dbfs/FileStore/lineage_input.csv"  # Adjust the path as needed
df_inputs = pd.read_csv(input_csv_path)

all_lineage = []
summary_stats = []

for _, row in df_inputs.iterrows():
    source_schema = row['schema']
    source_table = row['table']
    column = row['column']

    print(f"\nProcessing lineage for: {source_schema}.{source_table}.{column}\n")

    # Parameters Setup
    params = {
        "table_name": f"core_tst_std001.{source_schema}.{source_table}",
        "column_name": column,
        "include_entity_lineage": True
    }

    # Request Execution
    response = requests.get(url, headers=headers, params=params)

    # Response Handling
    if response.status_code == 200:
        data = response.json()

        # Flatten the JSON if needed
        upstream = pd.json_normalize(data.get('upstream_cols', []))
        downstream = pd.json_normalize(data.get('downstream_cols', []))

        # Add direction and column being processed
        for df, direction in [(upstream, "upstream"), (downstream, "downstream")]:
            if not df.empty:
                df["direction"] = direction
                df["source_column"] = column
                df["source_schema"] = source_schema
                df["source_table"] = source_table

                # Confirm 'name' column exists
                if "name" in df.columns:
                    df["linkage_type"] = df["name"].apply(lambda x: "direct" if str(x).lower() == column.lower() else "indirect")
                    df["comment"] = df["name"].apply(lambda x: f"Column '{column}' is directly used in this table/view" if str(x).lower() == column.lower() else f"Column is derived using '{column}' or other input columns")
                else:
                    df["linkage_type"] = "unknown"
                    df["comment"] = "'name' column missing in response"

        # Merge and collect
        lineage_df = pd.concat([upstream, downstream], ignore_index=True)
        all_lineage.append(lineage_df)

        # Summary statistics including downstream
        combined = pd.concat([upstream, downstream], ignore_index=True)
        upstream_count = upstream.shape[0]
        downstream_count = downstream.shape[0]
        distinct_col_count = combined['name'].nunique() if 'name' in combined.columns else 0
        distinct_tbl_count = combined['table_name'].nunique() if 'table_name' in combined.columns else 0
        direct_count = combined[combined['linkage_type'] == 'direct'].shape[0] if 'linkage_type' in combined.columns else 0
        indirect_count = combined[combined['linkage_type'] == 'indirect'].shape[0] if 'linkage_type' in combined.columns else 0

        summary_stats.append({
            "source_schema": source_schema,
            "source_table": source_table,
            "source_column": column,
            "upstream_count": upstream_count,
            "downstream_count": downstream_count,
            "total_distinct_column_count": distinct_col_count,
            "total_distinct_table_count": distinct_tbl_count,
            "direct_linkage_count": direct_count,
            "indirect_linkage_count": indirect_count
        })

    else:
        print(f"Request failed for column {column} with status code {response.status_code}")
        print(response.text)

# Combine all collected lineage info
if all_lineage:
    final_df = pd.concat(all_lineage, ignore_index=True)
    print("\nFinal Lineage Details (with linkage type and comments):\n")
    display(final_df)

    # Display summary statistics
    summary_df = pd.DataFrame(summary_stats)
    print("\nSummary Statistics per Column:\n")
    display(summary_df)
