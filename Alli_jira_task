import requests
import pandas as pd

# Token and URL Setup
token = "test"
url = "https://adb-67779643136828772.12.azuredatabricks.net/api/2.0/lineage-tracking/column-lineage"
headers = {
    "Authorization": f"Bearer {token}",
    "Content-Type": "application/json"
}

# Load input parameters from CSV
input_csv = "lineage_input.csv"  # Update this with your actual CSV file path
df_input = pd.read_csv(input_csv)

# Loop through each row in the CSV
for index, row in df_input.iterrows():
    catalog = row['catalog_name']
    database = row['schema_name']
    table = row['table_name']
    column = row['column_name']

    # Combine full table name
    full_table_name = f"{catalog}.{database}.{table}"

    # Parameters Setup
    params = {
        "table_name": full_table_name,
        "column_name": column,
        "include_entity_lineage": True
    }

    # Request Execution
    response = requests.get(url, headers=headers, params=params)

    # Response Handling
    print(f"\nProcessing: {full_table_name}, Column: {column}")
    if response.status_code == 200:
        data = response.json()

        # Flatten the JSON if needed
        upstream = pd.json_normalize(data.get('upstream_cols', []))
        downstream = pd.json_normalize(data.get('downstream_cols', []))

        print("\nUpstream Columns:\n")
        display(upstream)

        print("\nDownstream Columns:\n")
        display(downstream)

        # Optionally merge all into a single DataFrame with labels
        upstream["direction"] = "upstream"
        downstream["direction"] = "downstream"
        lineage_df = pd.concat([upstream, downstream], ignore_index=True)
        display(lineage_df)

    else:
        print(f"Request failed with status code {response.status_code}")
        print(response.text)
