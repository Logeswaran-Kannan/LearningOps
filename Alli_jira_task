from pyspark.sql.functions import col, explode, from_json, schema_of_json
from pyspark.sql import SparkSession

# Start Spark session
spark = SparkSession.builder.getOrCreate()

# Read the table
df = spark.table("mqs.dlt_quote_request")

# Convert Payload to string (safe for from_json)
df = df.withColumn("Payload_str", col("Payload").cast("string"))

# Sample a record to infer schema
sample_json = df.select("Payload_str").filter("Payload_str IS NOT NULL").limit(1).collect()[0][0]
json_schema = schema_of_json(sample_json)

# Parse the JSON string into structured data
parsed_df = df.withColumn("parsed", from_json(col("Payload_str"), json_schema))

# Explode drivers → incidents → claims
exploded_df = parsed_df \
    .withColumn("driver", explode("parsed.coreRisk.drivers")) \
    .withColumn("claim", explode("driver.incidents.claims"))

# Extract the fields
result_df = exploded_df.select(
    col("claim.claim_PRN").alias("claim_PRN"),
    col("claim.claim_ClaimType").alias("claim_ClaimType"),
    col("claim.claim_Date").alias("claim_Date"),
    col("claim.claim_DriverAtFaultInd").alias("claim_DriverAtFaultInd"),
    col("claim.claim_NcdLostInd").alias("claim_NcdLostInd")
)

# Display the result
result_df.show(truncate=False)
