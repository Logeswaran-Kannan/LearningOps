# Set your catalog and database
catalog_name = "your_catalog"
database_name = "your_database"

# Set the current catalog and database
spark.sql(f"USE CATALOG {catalog_name}")
spark.sql(f"USE {database_name}")

# Get all tables in the database
tables_df = spark.sql("SHOW TABLES")

# Get table names and their row counts
results = []
for row in tables_df.collect():
    table_name = row.tableName
    full_table_name = f"{catalog_name}.{database_name}.{table_name}"
    count = spark.table(full_table_name).count()
    results.append((full_table_name, count))

# Convert to a DataFrame for better display
from pyspark.sql import SparkSession
spark = SparkSession.builder.getOrCreate()
result_df = spark.createDataFrame(results, ["Table Name", "Row Count"])

# Display the result
result_df.show(truncate=False)
