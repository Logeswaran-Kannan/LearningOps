from pyspark.sql.functions import col, round

# ==============================
# INPUT: LIST OF TABLES
# ==============================
tables = [
    "db1.table1",
    "db1.table2",
    "db1.table3"
]

# ==============================
# RESULT CONTAINER
# ==============================
results = []

# ==============================
# PROFILING LOGIC
# ==============================
for table in tables:
    df = spark.table(table)
    total_count = df.count()

    # MQSQuoteId – not null & unique
    mqs_not_null = df.filter(col("MQSQuoteId").isNotNull()).count()
    mqs_distinct = df.select("MQSQuoteId").distinct().count()

    # EHUBQUEUEDDATETSTAMP – not null
    ts_not_null = df.filter(col("EHUBQUEUEDDATETSTAMP").isNotNull()).count()

    # Distinct controlled columns
    provider_distinct = [r[0] for r in df.select("provider").distinct().collect()]
    dataset_distinct = [r[0] for r in df.select("dataset").distinct().collect()]
    outputformat_distinct = [r[0] for r in df.select("outputformat").distinct().collect()]

    # Population metrics function
    def population_metrics(column):
        populated = df.filter(col(column).isNotNull()).count()
        nulls = total_count - populated
        pct = round((populated / total_count) * 100, 2) if total_count > 0 else 0
        return populated, nulls, pct

    driverPRN_pop, driverPRN_null, driverPRN_pct = population_metrics("driverPRN")
    driverPRNMap_pop, driverPRNMap_null, driverPRNMap_pct = population_metrics("driverPRNMap")
    vehiclePRN_pop, vehiclePRN_null, vehiclePRN_pct = population_metrics("vehiclePRN")
    errorMessage_pop, errorMessage_null, errorMessage_pct = population_metrics("errorMessage")

    # DATA – not null
    data_not_null = df.filter(col("DATA").isNotNull()).count()

    results.append((
        table,
        total_count,
        mqs_not_null,
        mqs_distinct,
        ts_not_null,
        provider_distinct,
        dataset_distinct,
        outputformat_distinct,
        driverPRN_pop, driverPRN_null, driverPRN_pct,
        driverPRNMap_pop, driverPRNMap_null, driverPRNMap_pct,
        vehiclePRN_pop, vehiclePRN_null, vehiclePRN_pct,
        errorMessage_pop, errorMessage_null, errorMessage_pct,
        data_not_null
    ))

# ==============================
# FINAL PROFILE DATAFRAME
# ==============================
columns = [
    "table_name",
    "total_records",
    "mqsquoteid_not_null",
    "mqsquoteid_distinct",
    "timestamp_not_null",
    "provider_distinct_values",
    "dataset_distinct_values",
    "outputformat_distinct_values",
    "driverPRN_populated",
    "driverPRN_null",
    "driverPRN_population_pct",
    "driverPRNMap_populated",
    "driverPRNMap_null",
    "driverPRNMap_population_pct",
    "vehiclePRN_populated",
    "vehiclePRN_null",
    "vehiclePRN_population_pct",
    "errorMessage_populated",
    "errorMessage_null",
    "errorMessage_population_pct",
    "DATA_not_null"
]

profile_df = spark.createDataFrame(results, columns)

display(profile_df)
