from pyspark.sql import functions as F
from pyspark.sql.types import StringType
import snappy

# ------------------------------------------------------------
# Config
# ------------------------------------------------------------
TABLE_NAME = "core_rl_test.flow.ehubstream"
TARGET_MQS_QUOTE_ID = "MQS-34354"

# ------------------------------------------------------------
# UDF: Snappy Decompress + UTF-8 Decode
# ------------------------------------------------------------
def snappy_decompress_utf8(payload_bin):
    try:
        if payload_bin is None:
            return None
        return snappy.decompress(payload_bin).decode("utf-8")
    except UnicodeDecodeError:
        return "UTF8_DECODE_ERROR"
    except Exception as e:
        return f"DECOMPRESSION_ERROR: {str(e)}"

snappy_decompress_utf8_udf = F.udf(snappy_decompress_utf8, StringType())

# ------------------------------------------------------------
# Read, Convert VARIANT â†’ BINARY, Filter, Decompress
# ------------------------------------------------------------
final_df = (
    spark.table(TABLE_NAME)
    # Extract MQSquoteId from headers JSON
    .withColumn("MQSquoteId", F.get_json_object("headers", "$.MQSquoteId"))
    .filter(F.col("MQSquoteId") == TARGET_MQS_QUOTE_ID)
    # Convert VARIANT payload to BINARY
    .withColumn(
        "payload_binary",
        F.expr("CAST(payload AS BINARY)")
    )
    # Snappy decompress
    .withColumn(
        "decompressed_payload",
        snappy_decompress_utf8_udf(F.col("payload_binary"))
    )
    .select(
        "MQSquoteId",
        "headers",
        "decompressed_payload"
    )
)

# ------------------------------------------------------------
# Display
# ------------------------------------------------------------
display(final_df)
