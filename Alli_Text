from pyspark.sql import functions as F
from pyspark.sql import types as T

# function to flatten json columns automatically
def flatten_df(nested_df):
    flat_cols = []
    nested_cols = []

    for column_name, dtype in nested_df.dtypes:
        if dtype.startswith("struct"):
            nested_cols.append(column_name)
        else:
            flat_cols.append(column_name)

    flat_df = nested_df.select(flat_cols +
        [F.col(n + '.' + c).alias(n + '_' + c)
         for n in nested_cols
         for c in nested_df.select(n + '.*').columns])

    if len(nested_cols) > 0:
        return flatten_df(flat_df)
    else:
        return flat_df

# filter by messageType in headers JSON
filtered = df.filter(F.col("headers.messageType") == "PRECOMP_RESPONSE")

# flatten payload automatically
flattened_payload = flatten_df(filtered.select("payload.*"))

flattened_payload.show()
