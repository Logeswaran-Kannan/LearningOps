# Databricks Python script to decompress Snappy inside VARIANT column and flatten
from pyspark.sql.functions import col, expr
from pyspark.sql.types import StringType
import snappy
import json

table_name = "core_tst.mqs_athn_mtr.dlt_raw_enrichments"

df = spark.table(table_name)

# Step 1: extract base64 snappy string
# assuming payload.data contains base64

df2 = df.withColumn("snappy_base64", col("Payload.rawEnrichments.data"))

# Step 2: decode and decompress
@udf(StringType())
def snappy_decompress(b64):
    import base64, snappy
    if b64 is None:
        return None
    try:
        raw = base64.b64decode(b64)
        out = snappy.uncompress(raw)
        return out.decode("utf-8")
    except Exception:
        return None


df3 = df2.withColumn("json_decompressed", snappy_decompress(col("snappy_base64")))

# Step 3: parse JSON
json_df = df3.withColumn("parsed", expr("from_json(json_decompressed, 'MAP<STRING,STRING>')"))

# Step 4: flatten
flat_df = json_df.select("*", "parsed.*")

flat_df.display()
