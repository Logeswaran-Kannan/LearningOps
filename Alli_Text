from pyspark.sql.functions import col, udf
from pyspark.sql.types import StringType
import base64
import snappy
import json

# Step 1: Load your table with VARIANT column (Payload)
df = spark.table("core_tst.mqs_athn_mtr.dlt_raw_enrichments")

# Step 2: Cast Payload to string to access as raw JSON
df_str = df.withColumn("payload_str", col("Payload").cast("string"))

# Step 3: Extract rawEnrichment.data using a JSON function
from pyspark.sql.functions import get_json_object

# Use get_json_object to safely extract the nested field
df_extracted = df_str.withColumn(
    "compressed_data",
    get_json_object("payload_str", "$.rawEnrichment.data")
)

# Step 4: Define a UDF to decode Base64 and decompress Snappy
def decode_and_decompress(base64_str):
    try:
        decoded = base64.b64decode(base64_str)
        decompressed = snappy.uncompress(decoded)
        return decompressed.decode('utf-8')
    except Exception as e:
        return None

decode_udf = udf(decode_and_decompress, StringType())

# Step 5: Apply decompression
df_decompressed = df_extracted.withColumn(
    "json_string",
    decode_udf(col("compressed_data"))
).filter(col("json_string").isNotNull())

# Step 6: Dynamically infer schema from the decompressed JSON
json_df = spark.read.json(df_decompressed.rdd.map(lambda row: row["json_string"]))

# Step 7: Preview the flat or nested structure
json_df.display()
